<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Arnav Jain, Nilesh Gupta, Aditya Kusupati, Jon Barron, Deepak Pathak and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f5b461;
  text-decoration:none;
  }
  body,td,th {
     font-family: 'Source Sans Pro', Arial, sans-serif;
     font-size: 16px;
     font-weight: 400
  }
  heading {
     font-family: 'Source Sans Pro', Arial, sans-serif;
     font-size: 19px;
     font-weight: 600
  }
  strong {
     font-family: 'Source Sans Pro', Arial, sans-serif;
     font-size: 16px;
     font-weight: 800
  }
  sectionheading {
     font-family: 'Source Sans Pro', Arial, sans-serif;
     font-size: 22px;
     font-weight: 600
  }
  pageheading {
     font-family: 'Source Sans Pro', Arial, sans-serif;
     font-size: 48px;
     font-weight: 400
  }
  .status-ongoing {
    background-color: #ffeaa7;
    color: #2d3436;
    padding: 2px 8px;
    border-radius: 4px;
    font-size: 12px;
    font-weight: 600;
  }
  .status-completed {
    background-color: #00b894;
    color: white;
    padding: 2px 8px;
    border-radius: 4px;
    font-size: 12px;
    font-weight: 600;
  }
  .status-underreview {
    background-color: #0984e3;
    color: white;
    padding: 2px 8px;
    border-radius: 4px;
    font-size: 12px;
    font-weight: 600;
  }
  </style>

  <title>Vansh Ramani - Ongoing Projects</title>
  <link rel = "icon" href = "../images/IITD.png" type = "image/x-icon">
  <meta name="Vansh Ramani Projects" http-equiv="Content-Type" content="Vansh Ramani Projects">
  <link href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:wght@200;300;400;600;700&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=PT+Sans:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="../css/darkmode.css">
  <script src="../js/darkmode.js"></script>
</head>

<body>
  <!-- Dark mode toggle button -->
  <button class="theme-toggle" onclick="toggleTheme()" title="Toggle dark mode">
    <i class="fa fa-moon-o" id="theme-icon"></i>
  </button>
<table width="840" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
<tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
	<p align="center">
		<pageheading>Ongoing Projects</pageheading><br>
		<a href="../index.html">← Back to Home</a>
	</p>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
	<tr><td> <sectionheading>&nbsp;&nbsp;Current Research Directions</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
		<td width="100%" valign="top">
			<p>
        I am currently exploring several research directions that build upon my experience in graph neural networks, 
        high-dimensional algorithms, and machine learning systems. 
        
        <br><br>
        <strong>Panorama Extensions:</strong> Building on my work at University of Copenhagen, I'm investigating 
        advanced techniques for high-dimensional nearest neighbor search, particularly applications to recommendation 
        systems and large-scale graph analytics.
        
        <br><br>
        <strong>Machine Unlearning:</strong> Following my internship at CMU, I'm working on formalizing unlearning 
        mechanisms with provable guarantees, exploring how machines can selectively forget information while 
        preserving essential knowledge.
        
        <br><br>
        <strong>Lifting & Bispace Optimization:</strong> Developing neurosymbolic architectures that combine the 
        expressiveness of neural networks with the interpretability of symbolic reasoning, particularly for 
        scientific applications.
        
        <br><br>
        These directions align with my goal of making AI systems more efficient, interpretable, and reliable 
        for real-world applications.
			</p>
    </td>
  </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
	<tr><td> <sectionheading>&nbsp;&nbsp;Papers Under Review</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
		<td width="100%" valign="top">
			<p>
        <a href="https://arxiv.org/abs/2510.00566" target="_blank" id="panorama">
          <heading>Panorama: Fast-Track Nearest Neighbors</heading></a>
        <span class="status-underreview">UNDER REVIEW</span><br>
        <em>Collaborators: Alexis Schlomer, Akash Nayar, <a href="https://di.ku.dk/Ansatte/?pure=en/persons/467373" target="_blank">Dr. Panagiotis Karras</a> (University of Copenhagen), 
        <a href="https://www.cse.iitd.ac.in/~sayan/" target="_blank">Dr. Sayan Ranu</a> (IIT Delhi), 
        <a href="https://pages.cs.wisc.edu/~jignesh/" target="_blank">Dr. Jignesh M. Patel</a> (University of Wisconsin-Madison)</em><br><br>
        
        PANORAMA is a machine learning-driven approach that tackles the ANNS verification bottleneck through data-adaptive 
        learned orthogonal transforms that facilitate accretive refinement of distance bounds. Our transforms compact over 90% 
        of signal energy into the first half of dimensions, enabling early candidate pruning with partial distance computations.
        
        <br><br>
        <strong>Key Contributions:</strong><br>
        • Data-adaptive learned orthogonal transforms for dimension reduction<br>
        • 2-30× end-to-end speedup with no recall loss across diverse datasets<br>
        • Integration with state-of-the-art ANNS methods (IVFPQ, HNSW, MRPT, Annoy)<br>
        • Evaluation on modern embedding spaces including OpenAI's Ada 2 and Large 3<br>
        • <a href="https://arxiv.org/abs/2510.00566" target="_blank">[arXiv Paper]</a>
        
        <br><br>
        <strong>Technical Innovation:</strong><br>
        • Energy compaction through Discrete Cosine Transform<br>
        • Cauchy-Schwarz inequality for bound computation<br>
        • Iterative zooming algorithm for progressive refinement<br>
        • Shared memory architecture for parallel processing
        
        <br><br>
        <strong>Experimental Results:</strong><br>
        • Tested on datasets up to 10,000 dimensions<br>
        • Consistent performance improvements across different data types<br>
        • Memory-efficient implementation suitable for large-scale applications<br>
        • Superior performance on image classification and location-based services
        
        <br><br>
        <em>Status: Under peer review</em>
			</p>
    </td>
  </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
	<tr><td> <sectionheading>&nbsp;&nbsp;Recently Completed Projects</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
		<td width="100%" valign="top">
			<p>
        <a href="#erudite" id="erudite">
          <heading>Erudite: Agentic Knowledge Graph System</heading></a>
        <span class="status-completed">COMPLETED</span><br>
        <em>Completion: July 2024 | Collaborators: IIT Delhi Research Team</em><br><br>
        
        Developed a multi-agent RAG pipeline for dynamic expanding knowledge graphs integrating 5+ sources 
        (Semantic Scholar/YouTube) using Claude Haiku, achieving interactive graph generation in 130s.
        
        <br><br>
        <strong>System Architecture:</strong><br>
        • Fault-tolerant architecture with parallel agent execution<br>
        • 3 retries + exponential backoff for robustness<br>
        • Modular templates for easy integration of new data sources<br>
        • Real-time knowledge graph expansion and updating
        
        <br><br>
        <strong>Performance Metrics:</strong><br>
        • Interactive graph generation in under 130 seconds<br>
        • Support for 5+ heterogeneous data sources<br>
        • 99.5% uptime with fault-tolerant design<br>
        • Scalable to millions of knowledge graph nodes
        
        <br><br>
        <em>Repository: <a href="https://github.com/VanshRamani/ERUDITE" target="_blank">https://github.com/VanshRamani/ERUDITE</a></em>
			</p>
    </td>
  </tr>

  <tr>
		<td width="100%" valign="top">
			<p>
        <a href="#optimized-bin-packing" id="optimized-bin-packing">
          <heading>Optimised 2-D Bin Packing for VLSI Gate Design</heading></a>
        <span class="status-completed">COMPLETED</span><br>
        <em>Completion: Dec 2023 | Collaborators: <a href="https://www.cse.iitd.ac.in/~preeti/" target="_blank">Dr. Preeti Panda</a></em><br><br>
        
        Optimized VLSI gate packing by benchmarking approximation methods and developing a visualization pipeline 
        for the 2D packing and wiring problem. Designed greedy and annealing algorithms achieving over 96% packing efficiency.
        
        <br><br>
        <strong>Technical Achievements:</strong><br>
        • 96%+ packing efficiency while minimizing wire length<br>
        • Multiple sorting heuristics implementation and analysis<br>
        • Comprehensive algorithm complexity evaluation<br>
        • Edge case handling and performance optimization
        
        <br><br>
        <strong>Algorithms Implemented:</strong><br>
        • Bottom-Left Fill (BLF) heuristic<br>
        • Best-Fit Decreasing Height (BFDH)<br>
        • Simulated Annealing optimization<br>
        • Custom genetic algorithm variant
        
        <br><br>
        <em>Repository: <a href="https://github.com/VanshRamani/Gate-Packing" target="_blank">https://github.com/VanshRamani/Gate-Packing</a></em>
			</p>
    </td>
  </tr>

  <tr>
		<td width="100%" valign="top">
			<p>
        <a href="#deepfake-detection" id="deepfake-detection">
          <heading>Comprehensive Deepfake Detection System with MTCNN and Fact-Checking</heading></a>
        <span class="status-completed">COMPLETED</span><br>
        <em>Completion: Nov 2023 | Collaborators: <a href="https://github.com/jdhruv1503" target="_blank">Dhruv Joshi</a></em><br><br>
        
        Developed a robust Deepfake detection model by optimizing two key components: an MTCNN-based frame-by-frame 
        classifier with EfficientNet and a fact-checking approach that matches audio to visual features.
        
        <br><br>
        <strong>System Components:</strong><br>
        • MTCNN for face detection and alignment<br>
        • EfficientNet for frame-by-frame classification<br>
        • Audio-visual feature matching for fact-checking<br>
        • Ensemble learning with weighted mean combination
        
        <br><br>
        <strong>Performance Results:</strong><br>
        • 93% accuracy in deepfake detection<br>
        • Award-winning performance at CodeWars competition<br>
        • Real-time processing capability<br>
        • Robust against various deepfake generation methods
        
        <br><br>
        <em>Repository: <a href="https://github.com/jdhruv1503/deepfake-detection" target="_blank">https://github.com/jdhruv1503/deepfake-detection</a></em>
			</p>
    </td>
  </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
	<tr><td> <sectionheading>&nbsp;&nbsp;Future Learning Goals</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
		<td width="100%" valign="top">
			<p>
        Looking ahead, I aim to broaden my understanding of machine learning fundamentals and explore new domains 
        that complement my current expertise in graph neural networks and high-dimensional algorithms.
        
        <br><br>
        <strong>Reinforcement Learning:</strong> I hope to get my hands into RL this semester, exploring how agents 
        learn optimal policies through interaction with environments. This connects naturally with my interest in 
        sequential decision-making and optimization.
        
        <br><br>
        <strong>Graph Signal Processing:</strong> Building on my graph learning background, I want to study how 
        signals propagate through networks and how classical signal processing techniques apply to graph-structured data.
        
        <br><br>
        <strong>Fundamental Probabilistic Models:</strong> I plan to study core probabilistic frameworks like 
        Markov Decision Processes (MDPs), Hidden Markov Models (HMMs), and Markov Logic Networks (MLNs) to 
        strengthen my theoretical foundations.
        
        <br><br>
        These areas will provide a solid mathematical foundation for tackling more complex problems in AI and 
        understanding the probabilistic underpinnings of modern machine learning systems.
			</p>
    </td>
  </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
      <td>
        <br>
        <p align="center"><font size="2">
        <a href="../index.html">← Back to Home</a> | 
        <a href="https://github.com/VanshRamani" target="_blank">GitHub</a> | 
        <a href="https://www.linkedin.com/in/ramanivansh/" target="_blank">LinkedIn</a>
        </font>
        </p>
      </td>
    </tr>
</table>

</td></tr>
</table>

</body>

</html>